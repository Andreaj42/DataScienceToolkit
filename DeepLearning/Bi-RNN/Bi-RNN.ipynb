{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfaddcd",
   "metadata": {
    "id": "1dfaddcd"
   },
   "source": [
    "# Sentiment Analysis using Bidirectional RNN\n",
    "Sentiment Analysis is the process of determining whether a piece of text is positive, negative, or neutral. It is widely used in social media monitoring, customer feedback and support, identification of derogatory tweets, product analysis, etc. Here we are going to build a Bidirectional RNN network to classify a sentence as either positive or negative using the sentiment-140 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead77e5d9f8e9f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ead77e5d9f8e9f2",
    "outputId": "3d316c63-081a-4210-aea1-399036f1e58a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "# from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04946fd2",
   "metadata": {
    "id": "04946fd2"
   },
   "source": [
    "## Step 1 - Importing the Dataset\n",
    "First, import the sentiment-140 dataset. Since sentiment-140 consists of about 1.6 million data samples, let’s only import a subset of it. The current dataset has half a million tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66291938",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66291938",
    "outputId": "61ba4460-ea86-41c0-ab3e-9de0cce457c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wget in /home/andrea/.local/lib/python3.9/site-packages (3.2)\n",
      "Archive:  sentiment140-subset.csv.zip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wget\n",
    "import wget\n",
    "wget.download(\"https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/sentiment140-subset.csv.zip\")\n",
    "\n",
    "!unzip -n sentiment140-subset.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1f36f",
   "metadata": {
    "id": "40f1f36f"
   },
   "source": [
    "## Step 2 - Loading the Dataset\n",
    "Install pandas library using the pip command. Later, import and read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01eec593",
   "metadata": {
    "id": "01eec593"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('sentiment140-subset.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7caff94",
   "metadata": {
    "id": "d7caff94"
   },
   "source": [
    "## Step 3 - Reading the Dataset\n",
    "Print the data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152f61d8",
   "metadata": {
    "id": "152f61d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['polarity', 'text'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767130ee",
   "metadata": {
    "id": "767130ee"
   },
   "source": [
    "‘Text’ indicates the sentence and ‘polarity’, the sentiment attached to a sentence. ‘Polarity’ is either 0 or 1. 0 indicates negativity and 1 indicates positivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e88434",
   "metadata": {
    "id": "93e88434",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4112b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today  coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0                      @kconsidder You never tweet  \n",
       "1         0                 Sick today  coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
       "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
       "4         0  @MrKinetik Not a thing!!!  I don't really have..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ce3de",
   "metadata": {
    "id": "df7ce3de"
   },
   "source": [
    "## Step 4 - Processing the Dataset\n",
    "Since raw text is difficult to process by a neural network, we have to convert it into its corresponding numeric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092c815f",
   "metadata": {
    "id": "092c815f"
   },
   "outputs": [],
   "source": [
    "# To do so, initialize your tokenizer by setting the maximum number\n",
    "# of words (features/tokens) that you would want to tokenize a sentence to\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "max_features = 4000\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d6c5dba8a27369",
   "metadata": {
    "id": "36d6c5dba8a27369"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@kconsidder You never tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Sick today coding from the couch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii fit says I've lost 10 pounds since last time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@MrKinetik Not a thing!!! I don't really have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0                       @kconsidder You never tweet \n",
       "1         0                  Sick today coding from the couch.\n",
       "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
       "3         1  Wii fit says I've lost 10 pounds since last time \n",
       "4         0  @MrKinetik Not a thing!!! I don't really have ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess the data : replace in all the text inputs r'\\s+' by a space ' '\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f62831",
   "metadata": {
    "id": "07f62831"
   },
   "outputs": [],
   "source": [
    "# fit the tokenizer onto the text using torchtext library\n",
    "# hint : set the tokens to lowercase\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: tokenizer(x))\n",
    "data['text'] = data['text'].apply(lambda x: [t.lower() for t in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca46cde748af33a2",
   "metadata": {
    "id": "ca46cde748af33a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000lines [00:00, 221822.73lines/s]\n"
     ]
    }
   ],
   "source": [
    "# create the vocabulary from the data\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3f95e4",
   "metadata": {
    "id": "fc3f95e4"
   },
   "outputs": [],
   "source": [
    "# use the resultant tokenizer to tokenize the text (convert text to sequences then to tensor)\n",
    "data['text'] = data['text'].apply(lambda x: [vocab[token] for token in x])\n",
    "data['text'] = data['text'].apply(lambda x: torch.tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703cf9a9",
   "metadata": {
    "id": "703cf9a9"
   },
   "outputs": [],
   "source": [
    "# and lastly, pad the tokenized sequences to maintain the same length across all the input sequences\n",
    "data['text'] = data['text'].apply(lambda x: torch.concat((x, torch.zeros(4000-len(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16fd3b91",
   "metadata": {
    "id": "16fd3b91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, print the shape of the input vector.\n",
    "data['text'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e01cd6d3ad26b",
   "metadata": {
    "id": "883e01cd6d3ad26b"
   },
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77b3a3930db9a7b1",
   "metadata": {
    "id": "77b3a3930db9a7b1"
   },
   "outputs": [],
   "source": [
    "# Create a one-hot encoded representation of the output labels using the get_dummies() method (and convert to tensor).\n",
    "# CODE HERE\n",
    "data = pd.get_dummies(data, columns=['polarity'])\n",
    "\n",
    "# Retrieve all the inputs vectors (X)\n",
    "X_data = torch.stack(data['text'].tolist())\n",
    "y_data = data[\"polarity_0\"]\n",
    "\n",
    "# Split train and test data using the train_test_split() method.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2d5d7c8eb54d61",
   "metadata": {
    "id": "3d2d5d7c8eb54d61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40000, 4000]), torch.Size([10000, 4000]), (40000,), (10000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shapes of train and test data.\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf1052",
   "metadata": {
    "id": "cacf1052"
   },
   "source": [
    "## Step 4 - Create a Model\n",
    "Now, let’s create a Bidirectional RNN model. Make a class to define the model.\n",
    "The model contains several blocks :\n",
    "\n",
    "* An embedding layer is the input layer that maps the words/tokenizers to a vector with embed_dim dimensions.\n",
    "* The bidirectional layer is an RNN-LSTM layer with a size lstm_out.\n",
    "* The Linear layer is an output layer with 2 nodes (indicating positive and negative) and softmax activation function. Softmax helps in determining the probability of inclination of a text towards either positivity or negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca7d6f",
   "metadata": {
    "id": "2fca7d6f"
   },
   "outputs": [],
   "source": [
    "class BiRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, lstm_out, output_dim):\n",
    "        super(BiRNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.birnn = nn.LSTM(embed_dim, lstm_out, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_out*2, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        text = text.long()\n",
    "        embedded = self.embedding(text)\n",
    "        outputs, (hidden, cell) = self.birnn(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        out = self.fc(self.relu(hidden))\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6ff5d9384153",
   "metadata": {
    "id": "d5b6ff5d9384153",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.cuda import is_available as cuda_is_available\n",
    "\n",
    "# Define constants\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 256\n",
    "lstm_out = 196\n",
    "num_classes = 2\n",
    "\n",
    "# Set the device to GPU if available, else to CPU\n",
    "device = torch.device('cuda' if cuda_is_available() else 'cpu')\n",
    "\n",
    "# Finally, instantiate the model and put it on the device\n",
    "model = BiRNNModel(vocab_size, embed_dim, lstm_out, num_classes).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6259c",
   "metadata": {
    "id": "87b6259c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the model summary to understand its layer stack.\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba69e07",
   "metadata": {
    "id": "fba69e07"
   },
   "source": [
    "## Step 6 - Training the Model\n",
    "Train the model for about 20 epochs with a batch size of 128. At each epoch, evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285392f5da11cd9",
   "metadata": {
    "id": "f285392f5da11cd9"
   },
   "outputs": [],
   "source": [
    "# Build the training and test dataloader\n",
    "y_train = torch.tensor(np.array(y_train))\n",
    "y_test = torch.tensor(np.array(y_test))\n",
    "\n",
    "loaders = {\n",
    "    'train' : DataLoader(TensorDataset(X_train, y_train), batch_size=128, num_workers=4),\n",
    "    'test'  : DataLoader(TensorDataset(X_test, y_test), batch_size=128, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56503641",
   "metadata": {
    "id": "56503641"
   },
   "outputs": [],
   "source": [
    "# Build the training loop (and evaluate at the end of each epoch)\n",
    "def train_model(model, epochs):\n",
    "    total_batches = len(loaders['train'])\n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_num, (text, polarity) in enumerate(loaders['train'], 1):\n",
    "            text, polarity = text.to(device), polarity.to(device)\n",
    "            polarity = polarity.long()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(text)\n",
    "            loss = loss_function(output, polarity)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_num}/{total_batches}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        train_losses.append(epoch_loss / total_batches)\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for text, polarity in loaders['test']:\n",
    "                text, polarity = text.to(device), polarity.to(device)\n",
    "                polarity = polarity.long()\n",
    "\n",
    "                output = model(text)\n",
    "                correct += torch.sum(torch.argmax(output, axis=1) == polarity)\n",
    "                total += output.shape[0]\n",
    "            accuracy = correct / total\n",
    "            test_accuracies.append(accuracy)\n",
    "            print(f\"Train epoch: {epoch+1}/{epochs}, accuracy on test dataset: {accuracy:.4f}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Test Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aed32d",
   "metadata": {
    "id": "25aed32d"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy and loss graphs captured during the training process.\n",
    "train_model(model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c393ec",
   "metadata": {
    "id": "f8c393ec"
   },
   "source": [
    "## Step 7 - Perform Sentiment Analysis\n",
    "Now's the time to predict the sentiment (positivity/negativity) for a user-given sentence. First, initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf1158",
   "metadata": {
    "id": "17bf1158"
   },
   "outputs": [],
   "source": [
    "twt = ['I do not recommend this product']\n",
    "# Tokenize it.\n",
    "twt = twt[0].lower()\n",
    "twt = tokenizer(twt)\n",
    "twt = [vocab[token] for token in twt]\n",
    "\n",
    "# Pad it.\n",
    "twt = torch.tensor(twt)\n",
    "twt = torch.concat((twt, torch.zeros(4000-len(twt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4b780",
   "metadata": {
    "id": "f1a4b780"
   },
   "outputs": [],
   "source": [
    "# Predict the sentiment by passing the sentence to the model we built.\n",
    "twt = twt.to(device)\n",
    "twt = twt.unsqueeze(0)\n",
    "model(twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1e865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
